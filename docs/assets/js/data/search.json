[
  
  {
    "title": "Tactility's second year",
    "url": "/posts/2026/01/07/tactility-second-year.html",
    "categories": "posts",
    "tags": "tactility, software",
    "date": "2026-01-07 20:00:00 +0100",
    "content": "The Tactility community and I have been working on many aspects over the past year: devices, apps, quality-of-life features for developers, and much more. Let‚Äôs take a close look.    How it started  At the end of 2023, I got inspired by Flipper Zero and decided that there should be an application platform for ESP32 devices. I wrote about this in my previous post, which explains its roots and past progress.  Now, two years later, the project has come a long way toward realizing that goal.  How it‚Äôs going: Platform growth and usability  A lot has improved in the past year, including support for more than 20 new devices. Counting incubating implementations, the total is now nearly 40. Since this week, there‚Äôs also support for the newer and faster ESP32 P4 chip. Various quality-of-life improvements were added and many additional apps have become available, but when you start the latest Tactility, the most obvious change is the switch to dark mode:   &nbsp;     As you can see, the launcher itself didn‚Äôt change much, but what did change a lot was the amount of available apps!  Apps  About a dozen apps were added, including a couple of internal ones that are now available as downloadable/installable external apps. The most exciting new app is the App Hub: a simple ‚Äúapp store‚Äù with downloadable applications. All of them are open source:   &nbsp;     Applications have been supercharged with a new app file format: Much like on Android, a single application file contains all the assets, and all the binaries for the supported microcontrollers. Thanks to this feature, building and developing apps is now easier and less error-prone than before.  Diceware is one of the new applications that makes use of the asset bundling: it contains a dictionary that is used to generate passwords. Some of the other additions include: a calculator, the game ‚Äú2048‚Äù, a serial console, off-grid chat and more.        Along with several settings apps, the Wi-Fi management is completely renewed. This is partly because of the introduction of devices with very small screens.  UI Scaling  During the development for the Cardputer, I found that many apps didn‚Äôt work well on its small screen. I needed to find a way to scale buttons and other controls down, so that I could fit more of them inside an app.  Because of that, UI scaling was introduced: when the display is smaller, the UI scales down with it. While still evolving, the scaling system makes almost all apps usable on the Cardputer.        &nbsp;     This is only the start, as I‚Äôm looking further into improving the UI on all sorts of devices, including 10‚Äù displays:       To make all these apps happen, I‚Äôve worked a lot on improving the workflow for app development.  Development  Another new app is called ‚ÄúDevelopment‚Äù and is accessible via the Settings menu. It‚Äôs inspired by Android‚Äôs adb: It allows a developer to install and run applications remotely over Wi-Fi. This makes the code-build-run cycle much faster. Building, installing and running an application remotely can be as fast as 10 seconds.  Developers use the tactility.py Python script to talk to the ESP32.   &nbsp;     Just as tooling for app development is important, so is the tooling for operating system development.  Automation  A lot of actions related to releasing required manual intervention. Whether it was Tactility firmwares, the SDKs or the apps: it was tedious and fully manual. And the problem got bigger as more devices, apps and features were being added.  Now, when Tactility code is merged, the firmwares become automatically available on the Tactility installer website. The SDKs also become automatically available to app developers in the same way. Apps are automatically bundled for delivery to the CDN, but they‚Äôre not uploaded automatically yet.       It took a lot of work to put it all in place, but it‚Äôs paying back already.  Before, I felt pressure to make new releases in order to share progress with the community. Thanks to automation, that pressure has been reduced considerably. Every new feature now automatically becomes available via new firmware downloads, within an hour after development has finished.  Freeing up that tedious manual work allows me to focus on more important things. And I‚Äôm not just saving time: it also enables the community to try out new features quicker!  Internal tech  There have been a lot of internal changes. I‚Äôll explain some of the most notable ones:  Configuration  It used to be difficult to deal with Wi-Fi settings and settings for other services: every time you‚Äôd flash a new firmware during development, it would reset these settings. I would work around this by manually changing these configurations in the project, but it was tedious to do so and they would sometimes accidentally be merged into the main project code. To fix this, I implemented provisioning from SD card: You can now have certain configuration files on an SD card to automatically configure the operating system. These files get imported at boot.  Core Driver technology  APIs for ‚Äúcore‚Äù drivers were introduced and are currently available for displays and touch input. When you use them, it disables the desktop and LVGL rendering systems, and gives a developer more direct access to the hardware.  This is intended for game development where rendering performance matters: LVGL and the GUI have limited performance and take up a decent chunk of memory. Now that developers can disable those layers of the operating system, they gain extra resources to develop high performance applications.  Language support and diagnostics  Applications used to be written in C exclusively. Thanks to some special tricks, I‚Äôve managed to put some C++ support in.  Another useful feature is the addition of a topbar icon that warns when the device is low on memory. This is mainly useful on ESP32 devices that don‚Äôt have external memory.       It‚Äôs now possible to provide translations for apps. This is not widely implemented yet across apps and currently only available for internal apps.  Sponsors  I‚Äôm grateful that several companies agreed to sponsor the project. Some are providing hardware while others provide services:  I‚Äôd like to thank these companies:    CLion for providing an ‚ÄúAll Products Pack‚Äù license   Elecrow for providing devices and peripherals   LilyGO for providing devices   M5Stack for providing devices and peripherals   unPhone, Hamish Cunningham, for providing an unPhone   Cloudflare gets a special mention as I‚Äôm using the free tier for DNS proxying and their CDN.  Special thanks &amp; closing words  In my closing words, I want to thank NellowTCS and Shadowtrance especially for their dedication in implementing many devices and apps over the past 2 years, and I‚Äôd like to thank everyone else who contributed code or in other ways! Your input and contributions have been immensely valuable!  If you have questions, feel free to join the Discord community or send me an email."
  },
  
  {
    "title": "Tactility...One Year Later",
    "url": "/posts/2025/01/06/tactility-one-year-later.html",
    "categories": "posts",
    "tags": "tactility, software",
    "date": "2025-01-06 20:15:00 +0100",
    "content": "Not a lot of my projects survive this long, so let‚Äôs take a look what made this one special.    How it started  It all started in December 2023, when I was considering to buy a Flipper Zero device.  I still don‚Äôt have one, but I got to borrow one from a friend (thanks, Hanneke!). Flipper Zero is a multi-tool/gadget for people who like to tinker with electronics or software. I won‚Äôt go into too many details, as you can read up on that in my previous post.  In short, I started re-using some of the Flipper Zero code and started building an application platform. Meanwhile, very little of that original code is still there, with the exception of some comments and maybe a few lines of code. I‚Äôve also implemented Tactility on a couple more devices:    Before we dive into some of the major changes, let‚Äôs talk about motivation:  Motivation  So what kept me going?  I think it‚Äôs mainly the variety of challenges that keep me interested in this project. One time I can focus on just writing an app, the other time I can dive into systems programming or driver development, another day I‚Äôll be busy with website development. There‚Äôs always something different to do.  I keep a list of issues, ideas and tasks in a document. Such documents generally tend to become large and can be a demotivator for me. The way I approach it now is that I see it more as a shopping list with no strings attached: Do I feel like fixing a bug? Or do I want to make something new? Or do I improve something that isn‚Äôt up to standards?  It seems that no-one has built something like this for ESP32 before - at least not as open source - so that gives me some motivation too.    And then there‚Äôs all the support I get from the lovely people in various Discord communities! They are awesome: They motivate me, and they help me take the right decisions. If you‚Äôre in one of those channels: Thank you for the support! üíô  Apps, continued‚Ä¶  There are about two dozen apps right now! That includes the various settings apps and some helpers like an alert, selection or input dialog app. You might have guessed it, but the launcher in Tactility is just a ‚Äúspecial‚Äù kind of app!  My plan for the launcher is for it to remain simple, so it works well on devices with smaller screens. I‚Äôve paid attention to details, such as the icons being displayed either horizontally or vertically depending on the screen orientation or size.   &nbsp;     The WiFi app is my favourite one:   &nbsp;     This was the hardest one to build, because of the complexity of WiFi itself. You might notice that the interface is heavily inspired by iOS. I paid extra care when it comes to security: passwords are stored with encryption on flash storage. The encryption is hardware-bound, so merely copying the data from the ESP32 shouldn‚Äôt help an attacker much.  The WiFi app is a good example to show you that I really care about this project.  Two of the more technical apps are the I2C Scan app and the GPIO app:   &nbsp;     The GPIO app shows the state of the electrical connections to the microcontroller. The I2C app shows which devices are connected to the selected I2C interface. Both apps can help a developer to debug issues with the hardware.  The settings list and the settings themselves are also regular apps:   &nbsp;     The display app is pretty basic. It allows the user to change the brightness and gamma of the display. Similarly, you can enable/disable charging and see how much power is left before the battery runs out. The USB app reboots Tactility in USB storage device mode. This allows you to access the SD card as if it were a USB thumb drive.  External Apps  One of the major milestones for me was getting applications to run from an SD card. I thought it was impossible for a long time, but apparently there‚Äôs official support for it! Not everything worked out of the box, but after some code changes, I had it running:   &nbsp;     I think it took less than a day to go from a prototype to a fully functional app. External apps also implied I had to build an SDK so people can build apps for it, so that‚Äôs what I did! It‚Äôs still a work in progress, but it‚Äôs already usable to a great extent.  Simulator  Shortly after writing my previous post, on January 21st 2024, I had a working simulator. Building this had a bunch of implications, because not all code was suitable to run on a PC. This includes all the microcontroller-specific parts such as WiFi, SD card and much more.  It motivated me to write a HAL: a Hardware Abstraction Layer. This layer of software allows me to talk to hardware devices without it being specifically tied to a platform.    The simulator helps me develop apps much quicker. Some bugs can be analyzed and fixed more easily. Trying out new UI layouts on the simulator is also much quicker. The speed is partially gained in compilation time, but mainly because I don‚Äôt have to wait for the ROM to flash to a device.  Website  Considering the big leaps, I decided to build a proper website somewhere in the second half of this year. I recently also registered the tactility.one domain name for it. This led me to design a logo, which improved over the course of a few weeks with the help of some friends and people online:    Because it looks like a fan, it works well as a progress indicator widget for the apps. This is another good example of how a relatively straight-forward task can snowball into many more.  Crashing with QR  Speaking of websites‚Ä¶ when Tactility crashes, it shows a QR code that you can scan:    When you scan the QR code on your phone, it allows you to open a website that displays the crash information:    Quickly after sharing this on Discord, people were asking me what that data was and whether I was keeping all the information on a server (I‚Äôm not), so I added a help and privacy button to the website recently.  Crash reporting via QR code is great for devices that aren‚Äôt always connected online. It‚Äôll make it easier for non-techies to give me basic info on their crashes, and it already helped me debug issues that otherwise were impossible to debug.  An operating system? An application platform?  This is one of the least technical changes. I guess it‚Äôs mostly a rebranding to call it an operating system instead of an application platform. Considering that there‚Äôs a launcher and apps, and you can develop applications with an SDK, and you can run apps from an SD card ‚Ä¶  and the whole thing runs on FreeRTOS (RTOS stands for Real-Time Operating System), I decided it is appropriate to call it an operating system.  It just sounds a bit cooler too, doesn‚Äôt it? ;)  That‚Äôs‚Ä¶ a lot!  So what started as a Flipper Zero experiment led to developing an operating system, an SDK, over 2 dozen apps, 2 websites and a logo. There is so much more to unpack and I‚Äôm just getting started!"
  },
  
  {
    "title": "The making of a platform",
    "url": "/posts/2024/01/15/the-making-of-a-platform.html",
    "categories": "posts",
    "tags": "tactility, software",
    "date": "2024-01-15 21:30:00 +0100",
    "content": "I got inspired by Flipper Zero and started developing an application platform for ESP32 touchscreen devices.    Prologue  Some time in mid-December, I was wondering if I should buy a Flipper Zero device. The official website describes it as follows:     Flipper Zero is a portable multi-tool for pentesters and geeks in a toy-like body. It loves hacking digital stuff, such as radio protocols, access control systems, hardware, and more. It‚Äôs fully open-source and customizable, so you can extend it in whatever way you like.    (image by Flipper Zero)  I‚Äôll refer to F0 instead of Flipper Zero in the text below.  F0 allows you to play around with technologies such as BlueTooth, USB, infrared, NFC and much more. It offers a neat software development platform so you can easily output graphics and communicate with peripherals. It also has a cute dolphin pet that levels up as you explore. Its software is very interesting and I found myself wondering whether I could port the code to another microcontroller (MCU).  ESP32 has been my favourite MCU for the past few years. Most variants of the hardware come with a multi-core 240 MHz CPU, WiFi, bluetooth, 520kB of RAM (expandable to 8MB), several megabytes of storage and a bunch of wired connectivity options. It‚Äôs roughly the size of a postage stamp (18 x 25.5 x 3.1 mm) and it costs about 2 EUR before adding a USB port and a battery to it. For those who are interested: Flipper uses an STM32WB55 MCU.   (image by Espressif.com)  My porting efforts didn‚Äôt start out smoothly, but one thing led to another and 3 completely separate iterations later, I‚Äôve got something that looks usable. The result is an application platform called Tactility.  Originally, I intended to port the F0 project partially to ESP32 with as little deviation from the original as possible.  I first started with copying a ton of code and removing the bits that weren‚Äôt needed (yet) or that were blatantly incompatible. This was not a successful approach: once everything compiled, it was too hard to debug memory corruption issues.  In a second attempt to make a Flipper-like platform, I tried to make everything from scratch. It didn‚Äôt take long for me to realise that it was way too much work and I found myself copying in more and more bits from the Flipper project.  In my third and final attempt, I did something in-between: I started building up the platform with mostly existing F0 code. The main difference was that I was importing smaller bits and verifying them before moving on to the next feature. I also wasn‚Äôt afraid to implement certain things radically different if it was beneficial to the project. This worked better and I soon had a functional prototype. It featured an application launcher and the ability to start and quit applications:    Making the app makes the platform  Let‚Äôs dive into the software development journey‚Ä¶  It didn‚Äôt take long to build a few simple apps like ‚ÄúHello world‚Äù and one that showed memory information. I also had a ‚Äòdesktop‚Äô app at this point, but this wasn‚Äôt very challenging as it just lists the installed applications and launches them when you click on them.  When I set out to make a Wi-Fi service and related app, I didn‚Äôt know just how much it would change the entire platform! A good Wi-Fi app does a lot more things than you‚Äôd expect. Not only is it multi-threaded, you also need to store settings. And then there‚Äôs the increased complexity in UI and user experience.  As I was making this feature, it resulted in a complete change of the platform. I started with a simple screen to toggle Wi-Fi on/off. So far so good. Then I needed an additional screen so the user can enter credentials to connect to a network. This almost doubled the amount of code and suddenly the app had to manage ‚Äúwhich screen should I show - and when?‚Äù.  I decided to split the Wi-Fi app into two separate apps: one for the Wi-Fi overview and one for connecting to a new network. To implement this, I now had to support:    Launching an app from another app, and being able to return to the original one.   Launching an app with parameters, because I wanted to have the SSID field pre-filled when you pressed on it in the Wi-Fi overview.   Storing the Wi-Fi credentials.   ‚Ä¶ securely, so I had to implement encryption/decryption ‚Ä¶   ‚Ä¶ and I had to find a way to store the decryption keys in a safe (enough) manner.     What‚Äôs in an app?  Similar to Android and Flipper Zero, I created a ledger that defines a user app. It looks like this:  static void app_show(App app, lv_obj_t* parent) {     lv_obj_t* label = lv_label_create(parent);     lv_label_set_text(label, \"Hello, world!\"); }  const AppManifest hello_world_app = {     .id = \"helloworld\",     .name = \"Hello World\",     .icon = NULL,     .type = AppTypeUser,     .on_start = NULL,     .on_stop = NULL,     .on_show = &amp;app_show,     .on_hide = NULL };   This is a functional app. It shows the text label on the screen and nothing more. It almost looks like object-oriented programming. In fact, I might create a C++ wrapper in the future.  Background services work in a similar manner. The main difference is that they don‚Äôt define on_show, on_hide, an icon or a human-readable name.  App lifecycle  When you have apps starting other apps, you can consider it as a stack, which you aproach as LIFO or ‚ÄúLast In, First Out‚Äù: The last app that is put on the stack is the one that is shown to the user. It is also the first one to be closed before  you can get back to the app that was launched before it.  Starting an app and closing goes like this:     Create the app (allocate data)   Create the views (UI) for the app and show them   Hide the app and destroy the views   Destroy the app (free up data)   When app A starts app B, then the views of app A would be destroyed as the app is hidden, but app A itself would not be destroyed. When app B is closed and destroyed, the views of app A would be re-created and shown again.  Once I was able to launch apps onto a stack, I wanted to be able to launch them with certain parameters. Flipper Zero originally just passed a string, but I wasn‚Äôt a fan of that: command line arguments are terrible to process. Instead, I opted to use ‚Äúbundles‚Äù like on Android. A bundle is a sort of flexible dictionary that maps strings onto a specific set of types. It‚Äôs a simplified in-memory database (key-value store) with a flexible type system, while still using explicit typing.  This is how bundles work on Tactility:  // Make a bundle and store some data in it Bundle bundle = tt_bundle_alloc(); tt_bundle_put_bool(bundle, \"is_enabled\", true); tt_bundle_put_int(bundle, \"count\", 42); tt_bundle_put_string(bundle, \"label\", \"Hello, world!\");  // Check if the key and value exist... int value; if (tt_bundle_opt_bool(bundle, \"some_key\", &amp;value)) {     // ... }  // This one crashes if the key doesn't exist: bool is_enabled = tt_bundle_get_bool(bundle, \"is_enabled\");   Security and risk  Typing the Wi-Fi password on a touchscreen was becoming tedious. It was happening after every reboot. That‚Äôs why I needed to store the Wi-Fi credentials on the device. Once encrypting and decrypting was working, I still wasn‚Äôt done. The problem with encryption is that you need to store the secret that decodes the encrypted data. You can ask the user every time for a password to decrypt, but then you‚Äôve got yourself the same problem as when entering the Wi-Fi password manually: that‚Äôs tedious!  The most simple way to approach this, is to create a reasonably safe random set of numbers as the key, and store that key somewhere safe. This approach is not safe if an attacker has physical access to your device: they can connect via USB and fetch all the data from the flash memory (all the partitions on disk). This holds the encryption key and the encrypted data.  This was pretty bad, but the solution was fairly obvious: enable boot protection and flash encryption. The problem with these features is that they are not easy to set up. Most hobby developers won‚Äôt bother. So, instead, I opted to show a warning when a credential is stored on an unprotected ESP32.  It didn‚Äôt sit right with me. I knew most hobby devs won‚Äôt bother with setting up these security features. I knew there wasn‚Äôt much I could do to make it safe, but I found a way to make it better: If I can use some kind of secret information that isn‚Äôt readable from flash, but also isn‚Äôt easily available via the USB interface, perhaps I can mix this into the cryptographic key?  That‚Äôs where the eFuses come in: An eFuse is a programmatic fuse. You can blow the fuse once with software, and that‚Äôs it. Each fuse can be seen as a single bit of data, so if you have enough fuses, you can create a storage mechanism.  The ESP32‚Äôs eFuses already offer 6-8 bytes of random data. There is more data space, but it‚Äôs all set to 0 by default. With the hardware identifier, I could now create the private key as follows:    Make a buffer with 32 bytes and fill it with random data (in a safe manner with a seed).   Make another 32 byte buffer and fill it with the repeating hardware identifier.   Perform a binary XOR operation to combine both buffers.   An attack wouldn‚Äôt be as simple as just copying the data over USB. An attacker that wants to remain unseen would have to:    Copy all the flash data (complete backup)   Upload a malicious app to fetch the eFuse data   Re-flash the original data   It‚Äôs not a lot more secure this way, but it sure takes a whole lot more effort. I‚Äôll still keep showing warnings when secure boot and flash encryption aren‚Äôt enabled though.  What‚Äôs next?  I‚Äôm still working on UI/UX improvements for the Wi-Fi app. The connection dialog doesn‚Äôt have a ‚Äúbusy‚Äù animation as it connects. At a later stage, I also want to have Wi-Fi auto-reconnect and have the option to have Wi-Fi enabled (and connecting) on boot.  Right now, I‚Äôm looking at writing some tests‚Ä¶"
  },
  
  {
    "title": "Building a handheld PC",
    "url": "/posts/2023/05/20/building-a-handheld-pc.html",
    "categories": "posts",
    "tags": "hardware",
    "date": "2023-05-20 23:00:00 +0200",
    "content": "I‚Äôd like to share with you my latest project: Decktility!    For several years, I‚Äôve been looking for a project where I could dump a bunch of creativity in. A project of my own, that would be challenging and rewarding. Preferrably a project that combines electronics and software. Handheld PCs always had a special place in my heart. Palm III was my first one, and a bit later I got my hands on a Sharp HC-4500. I was intrigued by the Yarh.io projects and early this year I considered buying a uConsole. The uConsole was supposed to be shipped in March, but currently it‚Äôs still pending. So with a bunch of ideas and motivation, I started my own handheld PC project: Decktility.  Initial design criteria  I wanted to challenge myself and push the boundaries of homebrew solutions. The Yarh.io Micro 2‚Äôs design was too crude for my taste. It was clearly limited by the hardware availability at the time of development. The Yarh.io documentation gave me a good understanding of what I was about to embark on. I set out to make device that looked more refined. I wanted the end result to be sufficiently light, and the battery life had to be at least a couple of hours.  At this point, I was already considering the BigTreeTech Pad 5 as a foundation, as this was the thinnest touchscreen and Pi combination that I could find. It seemed logical that I wasn‚Äôt going to make a foldable device. Making a foldable device would pose several problems:     The Pad 5 would introduce about 15 mm thickness on one side, while the side with the keyboard would be at least about 20 mm thick considering an 18 mm 18650 battery cell and a case. 35 mm would not be acceptable. I considered a regular flat lipo, but I didn‚Äôt like that they get spicy when they short-circuit.   Hinges are difficult to implement well. The screen part would be heavy, and you don‚Äôt want it to open/close while typing.   So the decision was made: it was going to be a package size similar to Yarh.io Mini 2 and uConsole.  Prototyping  Before starting the 3D design, I bought some basic components online. This allowed me to measure them, so I could get an idea of how much space each component would take up. It also enabled me to start building up a prototype:    Just like the wiring in the assembly guide, I started by building up the power delivery: A USB battery management system (BMS) that can charge two 18650 lithium cells, paired with a 5 V step down converter as the Pi, keyboard and fan would require 5 V. I used a USB-C PD tester to verify the power while charging.  Once that was working, I added some breadboard wires and connected the Pi:    I found out that that the BMS was getting quite hot while charging. It was stepping up the 5 V from USB to about 8.4 V that the batteries require. Increasing the voltage is much less efficient than decreasing it, so there is more heat involved. This implied that I would need to accomodate cooling for this scenario. 45 C is not too bad in open air, but it wouldn‚Äôt be great in an enclosure, where the Pi would generate heat too.    In theory, having a battery, a switch and a Pi is going to result in a working product, but what if the battery was running low? If the power switch would remain on, it would drain and damage the battery. To solve this problem, I introduced an Arduino Nano. The Arduino would end up doing many things, but it started  with reading the voltage from the battery. To do this, I added two resistors with a high resistance value, because they would always be connected to the battery and thus leak power. By selecting 2.2M R and 3.9 MR, they would leak only 0.82 ŒºA (5 / (2200000 + 3900000)). That‚Äôs about 4.1 ŒºW, or in other words: it would take 203252 days to drain a 20 Wh battery. It‚Äôs not going to be problematic this way.    Now that we know when it‚Äôs safe to turn on the hardware, I had to add the ability to actually do so. I used a special kind of transistor - a power MOSFET (or ‚Äúpower FET‚Äù). The green PCB behind the cable mess holds the FET circuit:    Around this time, I started designing the CAD prototypes in OnShape. Many hours were spent measuring and drawing various components that would go into Decktility. I needed their 3D representation so I could do an integration test of sorts as I was creating the case:    In the early stages, I had to solve the dilemma of battery placement. Firstly, the battery had to be a counter-weight to the screen. It‚Äôs important that the device feels balanced in your hands. The screen and the battery are both quite heavy, so they cannot be on one side of the device.  I thought of 2 options for the battery: Either on the sides, as to create handles to grab the device, or I near the bottom center of the case. Having them on the sides would require two separate battery holders, and it would create a minimum height of about 7.5 cm for the bottom half of the device. I really liked the idea of the handles, but the downsides resulted in chosing the alternative setup.  Building  After working out the basic case design, it was time to print the first one. The first of many‚Ä¶    The massive FET board quickly catches the eye. The board in the picture is just to showcase how out-of-place it really is. I swapped it with a smaller one before continueing.  Swapping the FET board was harder than I thought. There are many pre-built modules available, but  most of them are built with N-FETs and not P-FETs. The N-FET boards are cheaper and easier to build, and result in an electronic switch that switches the GND wire. I would later find out that I need a P-FET, because I need a common ground connected at all times for the Arduino logic and the Pi logic to work together (for I2C communication).  In the end, I couldn‚Äôt find a small enough FET board, so I started reverse-engineering the existing one in my very first KiCad project:    and then rebuilding it on an experiment board:    I might make a custom PCB in the future. That way, I can add some connectors for various components, making the project easier to assemble.  Before the custom FET board, I was able to get most of the basic components working before adding the Pi to the mix. I would quickly find out that I didn‚Äôt have the correct wire thickness for the main power. I was using 20 AWG, which I use for drones that draw way more power. I would later replace them with 24 AWG wires.    When I was working on the Arduino firmware, I had a problem: every time I would upload a new firmware, the Arduino would restart. This would make the electronic switch go off, and thus restart the Pi. To overcome this, I would wire a second Arduino to I2C, isntead of using the one in the device. At a later stage, I also added a JST-SH connector to be able to easily disconnect the Arduino inside the device.    Charging status LEDs would be a nice touch. But adding 1 or 2 LEDs to the case would require a relatively considerable effort. And then it hit me: I could use fiber optics! Fishing wire (or flexible bracelet wire) can guide the light from the existing LEDs on the BMS to the edge of the case. All I would have to do is glue the wire in place. An overnight shipping and a quick experiment later, the theory was proven:    After a lot of iterations, the hardware was finally finished:    At this point, a custom I2C device implementation was enabling the Pi and the Arduino to talk to eachother.  The Pi could ask the Arduino about the charging status or the battery voltage, and the Arduino would report it back. I started investigating how to integrate it into a Linux desktop, so I read about dbus and upower. At first, the intention was to write a custom kernel driver, but then it hit me: What if I change my Arduino firmware so that it acts like an already supported Linux device? I did some research and settled on the LTC294x ‚ÄúBattery Fuel Gauges‚Äù implementation. It was one of the very few power-related Linux kernel drivers that were avaible in Raspberry Pi OS. The Arduino now acts like such a device, so it is fully supported in Linux.  I was stoked when I saw the battery icon appear for the first time:    Various learnings  Here‚Äôs a quick summarization of some noteworthy learnings that aren‚Äôt covered above:  As mentioned before, airflow was important. I had to cool the BMS board and also the Pi. Some holes for airflow would be insufficient. I ended up roughly aligning my components in the direct airflow of the fan. This ended up also as a bit of a constraint on the rest of the electronics design, as I wouldn‚Äôt be able to easily move the BMS board anymore.  Less fasteners(/parts) is better: The best fastener is the one you don‚Äôt need. If you create a groove and latch mechanism to save yourself some parts, it might be worth it! The cost for me was added complexity in the design.  Designing for ‚Ä¶ 3D printers? Or CNC milling? The plan was to initially make a 3D printed case and then later attempt an aluminum CNC-milled case. Designing for 3D printers is very different. It would require changes to make the cases millable on a 3 axis mill.  Electronics placement is difficult: Next to the airflow considerations, you also have to consider the amount of wiring needed to connect all the parts. I also wanted to make the build as small as I could. Finding the best trade-off is not an easy task. Then there is theory versus usability: Your SD card might fit in the slot, but is it easy to pull it out? Can you grip it with your nail?  3D printing - Chamfer is life: I used chamfers on overhangs as to not require support when 3D printing them. I also used chamfers on certain edges near case openings (e.g. ethernet and GPIO connectors), to slide objects into the case more easily.  3D printing - Manual painted-on supports: These are very handy if you have lots of overhangs, but only some of them need support. (used with SuperSlicer/PrusaSlicer)  3D printing - Parts can flex: If you make a battery tray, the pressure of the battery inside the case might budge it outward. This can result in your battery tray not being placeable when batteries are in it. More importantly: you should measure the flex and see if it‚Äôs bending outwards too much, because you don‚Äôt want a critical failure with lithium cells.  Use SSH to the fullest: I increased my dev cycle by using remote commands. I could execute my local Python remotely with ssh me@cyberdeck 'python' &lt; powermanager.py  Raspberry Pi 4 has more than two I2C buses: When you fry your CM4 I2C bus, you can use other GPIO pins to create extra I2C ports.  Naming your project matters: While ‚ÄúDecktility‚Äù is probably not the best name out there, it is a good name because it‚Äôs easy to remember, and it‚Äôs a unique name so an online search will easily turn up the correct results. You can use ChatGPT to help you find a good name. (Decktility refers to ductility/utility, where ductility is a wink towards the welder part in my online persona)  Closing words  If you want more details, check out the Decktility GitHub repository."
  },
  
  {
    "title": "OpenPyrojet Print Head Prototype",
    "url": "/posts/2022/04/15/openpyrojet-print-head.html",
    "categories": "posts",
    "tags": "hardware, software",
    "date": "2022-04-15 18:00:00 +0200",
    "content": "A few weeks ago, I joined the OpenPyrojet project. OpenPyrojet intends to build 3D printer technology based on thermal spraying. In this post, I‚Äôll show you how I assembled the print head prototype.    This is what the finished print head looks like:    How does the printer work?  The feedstock of the printer is a mix of micrometer-sized particles (e.g. metals or ceramics) with a fuel source like IPA or naphtha. A monofilament wire is inside the fuel chamber. Heating the wire creates a hot gas, which is then pushed out of a nozzle, mixes with air and catches fire. Due to the heat, the metal melts and hits a surface (substrate) to which it attaches.  Let‚Äôs begin!  To build a strong print head, we‚Äôre using multiple layers made from PCBs. These layers are stacked in the order as they are laid out below:    I first prepared the inlet and outlet. I need to connect Viton tubing to the print head, so I‚Äôm soldering small copper pipes (3 mm diameter) to the PCB. The picture shows a larger copper pipe, because I used the wrong size when taking pictures:    I started with adding solder to the pads:    Initially, the solder will likely not connect neatly all around the copper pipe. It might look like the picture below. I take some extra solder on my iron and then place the iron at the base of the copper pipe to fix this issue:    Another problem that might occur is when your solder smudges. I cleaned it off by wiping my (cleaned) soldering iron on it. It‚Äôs not problematic if there is some solder on the side, but I have to make sure it‚Äôs not sharp. That way, it won‚Äôt cut the Viton tubing later on:    When I used too much solder, the inlet became too narrow. I could‚Äôve desoldered it. Instead, I used a set of drills to carefully drill it out by hand. I kept increasing the drill diameter by 0.1 mm until the diameter was the right size:    Finally, I had a neat collar on the copper pipe:      The next step was to put the monofilament on one of the PCB layers. This monofilament is what heats up the fuel, which causes the fuel to eject through the nozzle. The filament gets sandwiched between the nozzle PCB and the PCB that holds the connector. I store the filament in a folded sheet of paper:    First I cut the filament to size. We make it as wide as possible, so the thickness of the glue won‚Äôt interfere with the electrical conductivity:    Combining them is tricky, because the filament won‚Äôt lay still on a flat surface. I used some CA glue on the edges to keep it into place. I learned later that glue is not the ideal way. In the future, I will tape it near the edges if the PCB with some kapton tape.    The nozzle PCB layer had holes that were too small in diameter. I widened them by hand with some cheap drills, slowly increasing the diameter 0.1 mm at a time:    When attaching the nozzle PCB to the connector PCB, I start with a single row of screws:    It‚Äôs important to tighten the screws evenly, so initially all screws are kept loose. I then tightened them carefully and as evenly as possible. When everything stops sliding around, I start measuring resistance before continueing to tighten further. The resistance measurements are repeated until the values are in an acceptable range.    I had to make sure that the nozzle plate wasn‚Äôt crooked, like in the picture below:    The prepared PCBs are ready to be combined. I took 8 pieces of M2 x 10mm and some M2 nuts to match. I also used medium-strength loctite:    At this point, I have a finished physical assembly:"
  },
  
  {
    "title": "Hobby CNC electronics",
    "url": "/posts/2021/12/28/hobby-cnc-electronics.html",
    "categories": "posts",
    "tags": "hardware",
    "date": "2021-12-28 00:00:00 +0100",
    "content": "I recently started building an IndyMill CNC router. In this post, I‚Äôll share some progress and decisions I‚Äôve made when working on the electronics cabinet of this build.    Please note that everything written below is written in the context of hobbyist CNC router hardware.    A brief intro to hobby CNC routers  A CNC router (or mill) is not a complex machine. Its main job is to move a spindle (~ drill) along the X, Y and Z axis at a specific speed. In a hobby router, you generally use stepper motors, just like you would in a 3D printer - albeit perhaps more powerful ones.  These stepper motors require a lot of power, so they are controlled by drivers. A driver is a device that gets low voltage input signals and translates it into high voltage power signals for the stepper motors.  The drivers themselves are controllerd by a controller. The controller is the heart and brains of the CNC mill: It translates a ‚Äújob‚Äù into signals that it sends to the drivers.  A CNC ‚Äújob‚Äù is defined by ‚Äúgcode‚Äù file. This contains all the commands for the machine to execute. A basic command could be something like ‚Äúmove the spindle 2mm along the X axis‚Äù.  There are few more bits and pieces that I‚Äôm not talking about here, but these are the main things a hobbyist CNC router is about.  Choosing a cabinet  The first hard part is to find a cabinet that fits your needs. Here were some of my considerations:    Large enough (to work comfortably and to have space for upgrades)   Affordable (cabinets often cost hundreds of euros)   Easy to work with (drilling holes)   I settled on a cabinet from the German company BoxExpert. I chose the 600 x 400 x 200 mm size. It comes with a transparent door that allows me to see the status LEDs of the hardware inside, and it comes with a metal plate to mount hardware on. I paid about 82 EUR including shipping, so that was reasonable.  Mounting options  Initially, the plan was to mount the hardware directly to the plate. This has one major issue: you can‚Äôt change the layout at a later time. Imagine having to start drilling holes into it while there‚Äôs already hardware mounting!  DIN-rails were the answer to this! Not only did they help with strengthen the steel mounting plate, they allow me to change the entire setup freely at any time. There are lots of helpful DIN-compatible components out there that helped me in making my build clean.  Cabinet Layout  To make the cabinet layout, I used InkScape. A vector graphics editor like that (or Affinity Designer and many others) is ideal for me: I created a 600 x 400 pixel image, where each pixel represents a millimeter. The end result looks like this:    The yellow marked areas are space in the box that is unusable.  Some considerations included:    Separating high power components from lower power components   Separating AC from DC components   Ensuring everything is grounded   Cabinet Airflow  Although airflow isn‚Äôt super critical, it‚Äôs important to have at least some. We‚Äôre not generating a lot of heat inside the cabinet, but since it‚Äôs a water-proof cabinet, we want to create some airflow.  I wanted to have a rough idea of how different kinds of airflow would behave, so I used the free tier of SimScale to model some scenarios. Simulating airflow for the cabinet is overkill for a project like this, but it was fun to experiment with.  The first design has an intake fan on the bottom of the cabinet and an exit hole on the top-left. The downside of this designis that we can‚Äôt put the cabinet on a flat surface without obstructing the airflow:    The second design has an intake fan on the bottom-left and the outtake hole on the top-left:    The last design is the one I ended up chosing, but both were viable options.  Mounting the DIN rails  The first real build step was mounting the DIN rails on the steel plate of the cabinet. I used a medium-strength thread lock for the nuts and bolts. I also ensured that the plate could be grounded by drilling an extra hole for grounding.    Mounting the first components  Once the rails were ready, it was time to try out the first components: The top row has all 4 stepper drivers, connected to the power supply below. I‚Äôm using Wago clamps to tie it all together. The power cord is temporary:    DIN mounting options  There are a lot of DIN parts on Thingiverse. A lot of the DIN brackets that I used come from there. Some of them were custom. The controller and fan brackets are a remix of an existing ones on Thingiverse:      Finish mounting the components  The CNC controller that I‚Äôm using as Grbl32bits board from Makerfr. I‚Äôve mounted it together with its power supply and the fan controller in the below picture:    Finishing the cabinet  The next step was drilling holes in the cabinet to facilitate all the connectors:    In case you are wondering: yes, that is indeed my living room table being used as a workbench. My wife is awesome for putting up with it.  After everything is wired up, the cabinet is finished!        You can find my collection of 3D printable parts here."
  },
  
  {
    "title": "Designing for privacy: A thought experiment",
    "url": "/posts/2021/09/05/designing-for-privacy.html",
    "categories": "posts",
    "tags": "",
    "date": "2021-09-05 00:00:00 +0200",
    "content": "Apple‚Äôs plans have been widely critiqued. This was breach of trust for me, and it made me reconsider my choices of software and hardware. It also made me think of how we, as software engineers, could do better in terms of privacy. Below is a thought experiment.    The Idea  A software development platform, where the user is - by default - the sole owner of its data.  For offline applications, this is easy. Anything you store on your own devices remains in your ownership. Any offline application automatically passes this criterium.  For online applications, this becomes a different story. Online applications imply that a server is a mediator that processes and likely also stores some of your data. There are few exceptions, such as instant messengers that implement E2EE.  This made me wonder: What if we wrote more software on E2EE principles? What if a calendar or contacts service wouldn‚Äôt be able to read your calendar entries or contacts? And how do we move these concepts to more complex online applications? Sometimes the server simply must know some data. Even an E2EE messenger needs to have a basic understanding of the recipient that you want to communicate with. Or perhaps you want to expose calendar through CalDAV, or share an entry from your address book via email? We want the user to remain the sole owner of its data, but we should also give the freedom to open up that data.  Let‚Äôs get more specific  In my thought experiment, all user data is encrypted before handing it over to an online service.  This service can do few things:  1. Act as a storage system for encrypted data of our user  It acts as an online file system. The user‚Äôs applications can store their data here.  2. Act as a proxy/broadcasting system for applications  Applications can send encrypted data to other applications, within the user‚Äôs ownership.  For example: The user has a calendar application on their phone and on their desktop. When the user adds an address on their phone, the desktop needs to be notified to update its data.  3. Act as a proxy/broadcasting system for other service hosts.  For example: The user has a calendar application and whishes to share a calendar event with to a friend. This friend might be hosted on the same service, but he might also be hosting their own or use a third party to host it.  Authentication  If(!) this setup could work for various types of applications, we don‚Äôt want individual applications to have access to our secrets like our private key or password. This cryptographic secret is still required to be able to encrypt the data. To fix this, we could introduce a ‚Äúcontroller‚Äù application that runs on each device. Consider this controller similar to how you can log in with iCloud on your iPhone, giving all iCloud-enabled applications access to your iCloud data, but not your iCloud credentials or cryptographic secrets.  This controller would serve the following purpose:     The controller authenticates directly with the main service that holds/transfers our encrypted data.   The controller is a proxy to the applications on the local system that the controller is running on. It exposes an API to enable this.   Local applications must get permission to connect with the controller. This requires direct interaction, instigated by the controller‚Äôs UI.   Mitigations and considerations     Ensure that there is an upgrade path for cryptographic algorithms.   Users must make sure to not lose their crypto secrets, because that would mean irreversible loss of access to their data. We need to consider ways to easily backup passwords. Perhaps we can consider having different types of passwords (e.g. word list, hex byte list, passphrase, etc.)   The online service might be deployed by the users. There might be a need for such services to talk to each other.   Closing words  I‚Äôd like to hear your thoughts on this thought experiment, so feel free to contact me through twitter/email via my main website."
  },
  
  {
    "title": "Google Analytics IP anonymization is a joke",
    "url": "/posts/2021/07/08/google-analytics-ip-anonymization-is-a-joke.html",
    "categories": "posts",
    "tags": "",
    "date": "2021-07-08 22:30:00 +0200",
    "content": "Google Analytics, the popular data gathering and statistics analysis tool, has a feature called IP Anonymization or IP Masking. The name is kind of a joke to me, because it isn‚Äôt nearly as anonymous as it sounds. Let‚Äôs take a deeper look at this feature!    The best point to start with is the official documentation. In its current state (July 8, 2021) it tells us:     When a customer of Analytics requests IP address anonymization, Analytics anonymizes the address as soon as technically feasible. The IP anonymization feature in Analytics sets the last octet of IPv4 user IP addresses and the last 80 bits of IPv6 addresses to zeros in memory shortly after being sent to Google Analytics. The full IP address is never written to disk in this case.   What‚Äôs an IP?  (feel free to skip ahead)  Your internet connection is identifyable by something that is called an ‚ÄúIP address‚Äù - or in short: ‚ÄúIP‚Äù. Most people have an IP that looks somewhat like this: 101.102.103.104. For some devices and internet providers, this might change over time, but for many it stays the same over the course of years. This means that an IP can be used to help identify a user across the internet.  When you browse the web or use applications, your computer talks with various other machines and they can locate each other through these IP addresses. Google Analytics is one of those entities that you can communicate with.  So how does Google store your IP?  When a computer is talking to Google Analytics and asks it to enable IP anonymization, something happens to it before Google stores it: the last part of that number series is removed - replaced by a 0. If your IP would be 101.102.103.104, then it would look like this after Google‚Äôs anonymization process: 101.102.103.0  The removed number is always in the range of [0 - 255]. This means that Google is only 256 guesses away from recovering your ‚Äúanonymized‚Äù IP address! ‚ÄúWhy is this a problem?‚Äù you might ask:  256guesses aren‚Äôt a whole lot. It‚Äôs likely that Google stores other kinds of information along your IP. Data is the bread and butter that gets the analytics engine running after all. Let‚Äôs take a further look‚Ä¶  Firstly, when taking a look at the range of .0 to .255, not all the related addresses are necessarily in use, which could reduce the sample set.  More likely, the program or website that is using analytics is sending other data through. A common data point is a ‚Äúuser agent‚Äù. The user agent is a short definition of what kind of software is contacting the server. It can look like this: Homebrew/2.5.0 (Macintosh; Intel Mac OS X 10.15.6) curl/7.64.1. Depending on how unique your computer configuration is, this mere user agent is possibly unique enough to detect your computer in a group of at most 256 machines.  A user agent is just 1 data point. There are many more that one can think of to help define a user uniquely, and that are consistent across various applications or websites.  Why is this problematic?  Privacy  With sufficient data, Google has the ability to de-anonymize those IP addresses. With a known IP - especially combined with more data - one could easily cross-reference data from users across services.  We don‚Äôt know if Google does this, but we should be aware of the inherent risks of using Google Analytics. Both as a customer who runs Google Analytics with their software, and as an end-user who is browsing the web.  Even with the partial IP, Google can still make a rough estimate of your physical location. The documentation explains:     Geographic dimensions are later derived from anonymized IP addresses.   The power of words  While technically, the anonymization technique of Google does anonymize the IP address, it does so very poorly. Only partial anonymization is happening. Calling it that gives a false impression.  If someone would post your mobile phone number with only the last 2 digits removed in a public space, it would be easy for a caller to try all 100 numbers and see which one is the one where you pick up. Would you consider such a phone number anonymous? I know I wouldn‚Äôt.  So what can we do about it?  The average person on the web could pick one of the popular browser extensions to block advertisements and analytics, such as uBlock Origin and many more. Web developers could reconsider using Google Analytics. Google could use more clear language or it could simply not store partial IP addresses.  IPv6  So what about IPv6? Luckily, Google did better here: when IP anonymization is applied, the last 80 bits of data are removed. This gives a massively larger pool of possible addresses when attempting to recover an IP.  However, since most internet users use IPv4, this is not very relevant."
  },
  
  {
    "title": "Thoughts on multiplayer networking",
    "url": "/posts/2020/10/07/thoughts-on-multiplayer-networking.html",
    "categories": "posts",
    "tags": "software",
    "date": "2020-10-07 23:00:00 +0200",
    "content": "The topic of gaming and networking was brought up on the KorGE Discord server. This made me think about the various forms of networking stacks that I‚Äôve encountered in the past years, and some of the different considerations for their development.  The intention of this article is to give a glimpse into various approaches and considerations. It‚Äôs likely not complete or perfect, but I hope it will be useful for developers that are somewhat new to networking for games.    Server(less)?  Does your game logic require a central server to host your game? How much centralized control does your game need? And how much control are you willing to cease to the local machine, a third party or even one of your players? Answering these questions will lead to one of the main choices that you‚Äôll make when designing a network stack for your game.  Server with logic  This is the first type of server, and probably the most common one. I bet that if you‚Äôd ask 10 gamers what a multi-player server roughly does, this is what most of them will describe.  It is often a machine (or part of a machine) that all the players (clients) connect to. It that manages all the data and everything that happens in the game. It keeps all the game state and ensures that all communication to the clients is happening properly.  The main benefit is that the server owner (most often the developer) is in full control of the game and everything that happens within it.  Peer-to-peer  With this approach, there simply is no server that runs game logic. A common peer-to-peer approach in gaming is that of master/slave:  All the clients would vote for - and elect - a ‚Äúsession master‚Äù. This machine would basically act as a server. To ensure that this special client wouldn‚Äôt be cheating, the other clients can still observe it and vote to un-elect this machine if things don‚Äôt appear to be going in order.  Another problem is that this session master would possibly get increased traffic in certain kinds of scenarios, like that of a first person shooter game.  Peer-to-peer games might still have some kind of server in their toolbox. For example: when there is a need of a lobby mechanism, a friend list, analytics, etc.  Server as multicasting component (no logic)  Although this isn‚Äôt entirely an approach on its own, a multi-casting server can be a tool for a serverless network setup. In the case of a peer-to-peer approach, it can help with the heavy lifting on the session master: The session master can leverage this machine to multicast messages to all the other clients, without sacrificing too much of its own bandwidth.  Network Protocols  Most games probably will solely rely on TCP/IP for its networking stack. This ensures that data arrives in order, or that it even arrives at all. Connections can still fail, of course, but at least the client knows it when data fails to send.  With UDP, this is different: Not only are you unsure about whether data (packets) arrive at their destination at all. There is also no guarantee about the order in which data is received, or even how many times a specific packet of data is received! The main reason to pick UDP would be due to its reduced latency. All that reliability of TCP costs extra bandwidth, because the recipient of the data must somehow acknowledge that data is received. UDP doesn‚Äôt have that kind of overhead.  To get best of both worlds, TCP and UDP can be combined. For example: You could send the audio data from a voice chat over UDP, while there is also an active control channel that manages some meta-data about the UDP link.  Another hybrid approach is reliable UDP, which uses UDP to create a reliable data connection. In this case you might increase your bandwidth and/or latency to resolve some of the reliability issues that a plain UDP protocol has. An example would be the acknowledgment of received packages. When a package is not acknowledged by the receiver, the sender can then retry sending it. Unlike with TCP/IP, a UDP protocol like this will retain full control over how this error-handling is done. With TPC/IP, such a failure to send would result in either a connection that stalls, or perhaps even disconnects! With a reliable UDP protocol, we can chose by ourselves which error scenarios are critical.  How much data?  Bandwidth is less of a consideration these days than it was before. In the 90s and early 2000s, bandwidth was simply a hard limitation. Games would often be designed to transfer at a rate of at most 56 kBps, because otherwise it would affect the target market. These days, most of us have broadband available. We‚Äôll still have to deal with differences in latency, though. Especially when it comes to mobile gaming, when the user is traveling with his device.  Bandwidth, however, is never free. More data might also negatively affect that precious latency, which can be crucial for game types that are fast-paced.  So how much data do you expect to send from each client? And how much does the server need to handle? Do you need to send a lot of updates in a second? Perhaps you have large amount of game entities that all move around? Will it require a lot of CPU capacity to process all that?  All these questions will influence the model of the data that you will come up with. For example: a real-time strategy game might have hundreds of game entities moving along your screen. It might not be feasible to send updates for all these entities to the server at a high speed rate.  Cheating and other forms of abuse  Catching cheaters and hackers in your game is one of the more difficult tasks. Banning the wrong person can be damaging to your brand or product.  While guarding against malicious usage should be a consideration during the game design phase, your network stack will also affect how much control you‚Äôll have over these scenarios: The more control you have over the network stack, the easier it will be to deal with cheaters and abuse.  Since anti-cheating is a form of security, we must consider the security principle of: Never trust the client-side application. In other words: You don‚Äôt know what a user does with your application, or whether he‚Äôs even using the application that you built. Or that it is used without modifications, or using it in the way that you thought up.  With that in mind, you can guess that a peer-to-peer approach is the riskiest when it comes to guarding your project. Since the clients are the server, the server might also be compromised. In this scenario, the clients might guard against a potentially malicious server. Perhaps they could even report potentially malicious servers‚Ä¶ this reporting mechanic by itself could then be abused, by a bunch of malicious clients: these clients could join a game and vote another user onto a ban list of some sort. As you can see: it‚Äôs complicated!  When a player breaks the game rules, it‚Äôs often easily visible to the players (and the server). In these scenario‚Äôs, it‚Äôs relatively easy to guard against it. When cheaters mimic real-world network scenarios, it becomes much harder. For example: a player connected to a wired network in a peer-to-peer game might use a foot switch to control when the outgoing data can exit his network. Imagine this player is in a first person shooter game, and he‚Äôs about to go around the corner to see (and attack) an opponent. He disconnects the receiving end of the network cable with his foot, walks around the corner, and shoots his opponent. His opponent didn‚Äôt receive his position, so he doesn‚Äôt even know he‚Äôs lost yet! At first, this looks like regular lag, but it starts to become more suspicious when it happens more often‚Ä¶  So which approach is the right one?  In the end, your network stack design will depends on a lot of factors. While some games have more obvious approaches than others, I don‚Äôt think there is no cookie-cutter answer on how to tackle it. Instead of trying to give you such answer, here‚Äôs a summation of the main questions that will help you decide on your own stack:     What kind of game do you have? (RPG/RTS/shooter/TCG/etc.)   What kind of data (and how much) is going on in a game? (how many players? how many active games at once?)   How much money are you willing to spend? (on servers? on development?)   How much control do you need? (in terms of your product/market, but also anti-cheating)   That‚Äôs it! I hope this is useful to someone out there‚Ä¶ If you‚Äôd like to send me feedback, you can find my contact info on my personal website.  Happy development!"
  },
  
  {
    "title": "Building a charging case",
    "url": "/posts/2020/08/14/building-a-charging-case.html",
    "categories": "posts",
    "tags": "hardware",
    "date": "2020-08-14 02:00:00 +0200",
    "content": "I will take you through the steps I took to create a charging case for 3 chargers. I hope you enjoy reading about my successes, findings and failures.      Materials used:     3x compact lipo charger (ISDT Q6 in my case)   a case that is large enough to hold everything (mine was 464 x 366 x 176 mm internally, type ‚ÄúMAX 430S‚Äù on Amazon)   various electrical wire (silicon sleeved, I used 14 AWG for the power delivery spec that I wanted)   3x balance connector distribution board (search on AliExpress for ‚ÄúB6AC A6 Charger‚Äù)   power distribution board (optional)   6x 40 mm fan (can be more/less, depending on your ventilation requirements)   6x fan cover (e.g. plastic mesh)   switching power supply (24 V and 15 A)   top plate material (e.g. triplex)   a bunch of XT60 and XT30 connectors, including 3x top-mounted XT60 (see pics below)   220 V power outlet with switch and fuse (the same one as the Ender 3 Pro comes with)   (note: this might be incomplete)  These are some of the tools that I remember using:     Soldering iron   3D printer (optional)   Hot glue gun   Wire cutters   Knife   Heat gun (optional)   Tweezers and soldering stand   Multimeter   Something to cut out the top plate (e.g. drill, jigsaw and Dremel**   I also designed some parts:     ISDT Q6 bracket: STL, FreeCAD   Balance board support plate: STL, FreeCAD   These parts are optional, as you can also use pieces of wood or plexiglass to construct something similar.  The total cost as about EUR 250 with the ISDT chargers. Half of that amount was just the cost of the chargers, so buying a cheaper charger could save some money. I also bought some components that were optional (PDB, more fans, etc.) You could probably bring the total down to slightly below EUR 200 if you‚Äôre making some different choices here and there.  Steps  First, I bought a case. It was relatively cheap, and the only downside was that it is a bit heavy:      The next step was to start creating a bottom plate. I wanted to keep it detachable, so I bought some 3M Dual Lock. I added a bit too much in retrospect, so when I detach the plate, sometimes the sticky tape comes off rather than the Dual Lock:    On this bottom plate, I added the switching power supply. The main consideration here was to have it placed in such a way that the combined airflow of the power supply unit (PSU) was working well with the airflow of the chargers. Another consideration was how the placement would affect the center of gravity of the case, so it would be nice to carry.  I mounted the PSU on the wooden plate with standoffs, so that the airflow would be better. I also wanted to make sure that if the power supply ever got really hot (which I don‚Äôt expect), it wouldn‚Äôt be touching the wood:    Here it is placed in the case:    Similarly, I created a top plate. It rests nicely on the rim of the case, and due to the design of the case, the lid still closes perfectly.    I drew some edges on it, to visualize how much actual space was usable. That way, I wouldn‚Äôt be hitting the side of the case:    I made many sketches on paper before picking my preferred layout. I laid some of the components on the paper to see if it would work well. The considerations were: airflow, wire connections (amount of wire needed), space during charging (how close is everything to each other).  After that was done, I transferred my layout to the top plate:    And of course I verified it by adding the components on top:    At this point, I started prepping wires already. This would allow me to already connect the chargers and start charging. That way, I didn‚Äôt have to wait to the end of the project until I‚Äôd have a functioning charging setup!    As you can see, the rig was already functionally usable:    I wanted a single wire to go from the PSU to the rest of the electronics. This allows me to easily disconnect the electronics on the top plate from the PSU on the bottom for maintenance and testing. In theory, I could just solder all the XT60 connectors together, in parallel, and be done with it. I chose another path and bought a power distribution board (PDB) to make the job a bit prettier. This PDB also comes with a BEC, so I could easily add some LEDs to the case later, or add more electronics that require a lower voltage.  To this PDB, I added some extra BECs (step down converters) that will drive the fans. They are separate, as I need more current from it than the PDB will give me. The BECs allow me to regulate the voltage, effectively allowing me to change the speed of the fans.  I am adding XT60 and XT30 connectors, because I want the entire thing to be modular and easy to disassemble:    Originally, I had only 1 BEC. This provided insufficient power to start rotating all fans at the same time. I added a second BEC to solve this problem, but in the end it was still insufficient. The proper fix would be to have a setup where each fan gets its own switch. That way, they can all individually get their needed current spike to start spinning - but not at least not at the same time!    At this point I started cutting out the top plate:    Because I used triplex wood, and I‚Äôm not super experienced with it, the wood partially disintegrated when cutting into it. I used some 2 component epoxy filler to fix most of it:    To finish the top plate, I painted it black:    Also the fans were mounted:    Then the XT60 top-mounted connectors were added:    Because the chargers were shaped irregularly, and I needed to support the balance boards with something, I designed and printed out some parts. You can also buy some wood or plexiglass and cut out similar parts by hand. I used 2 component epoxy filler (yes, filler) to glue the charger brackets on:    Then I put the balance charging cables in place and glued in the supports for the balance board:      The lasts step was to connect everything:    And then the project was finished:"
  },
  
  {
    "title": "ESC fuse fix",
    "url": "/posts/2020/06/30/esc-fuse-fix.html",
    "categories": "posts",
    "tags": "hardware",
    "date": "2020-06-30 02:00:00 +0200",
    "content": "I ordered a bunch of RushFPV Mini Tank Stacks that were rated for 30 A and connected them to some DYS Samguk 2600 Kv motors without propellers. This minimal load blew the fuse on the ESC, making the ESC unusable. The result was that BetaFlight showed 0.01 V when a lipo was connected.    A friendly RushFPV customer support representative stated that this stack wasn‚Äôt meant for 5\" quadcopters and motors with such high Kv values. In my opinion, 30 A is 30 A, regardless of motor size, so I‚Äôm still under the impression that this stack just can‚Äôt deliver what it says on the specifications. Thanks to the help of the RushFPV CSR, I was advised to bridge the fuse. I was given some pictures as a guide, but decided to make a comprehensive photo write-up myself.  These are the tools that I used:     ultra-fine tweezers   soldering iron with (thin) chisel tip   copper wire (preferably single core)   clippers   If you plan to fix your own ESC, you should understand that removing the fuse (and shorting/bridging it) means that there is nothing preventing damage to the ESC if too much current is pulled through it. It can lead to smoke and fire if you abuse the ESC beyond its limits without this safety net.  First, let‚Äôs take a look at the fuse itself. It‚Äôs the green SMD component on the ESC:    As mentioned in the list of tools, I used a fine chisel tip:    Use the clippers to splice the wire length-wise. Then cut a smaller piece off that is a bit smaller than the size of the fuse:    Have your soldering iron on high heat (I put mine on 425 C) and add a little bit of solder. This solder will help spread the heat on the SMD component:    Start holding the fuse with the tweezers. Don‚Äôt put a lot of force on it, but make sure you grab hold of it:    Bring the soldering iron to the fuse (don‚Äôt push hard) and gently pull the fuse off with the tweezers:    The ESC will now look like this:    Add some fresh solder to the fuse pads. I used the sharp end of the chisel tip to set down my iron in a stable manner, and then I fed a little bit of solder into it:    Now place the tiny piece of copper wire, with the flat side down, between the ESC fuse pads.    Before you put the soldering iron down, make sure that you have some grip on the wire, as it will start sliding a bit when the solder is flowing. To solder it, just put your iron down on the copper bit and let the heat of the copper conduct into the solder and melt the solder into the copper:    That‚Äôs it, you‚Äôve now bridged the fuse!  You can test as follows:     Continuity test on fuse and ESC battery pads.   Power on the ESC with a battery and a smoke stopper.   Remove battery power, add the FC and do another power on test with the smoke stopper.   Remove battery power, connect setup through USB, re-connect power (with smoke stopper) and verify the voltage readout in BetaFlight"
  },
  
  {
    "title": "Making a Li-Ion battery pack",
    "url": "/posts/2020/06/06/li-ion-battery-pack.html",
    "categories": "posts",
    "tags": "hardware",
    "date": "2020-06-06 02:00:00 +0200",
    "content": "This post shows the steps involved in making a 2S pack with 21700 cells. This guide is also relevant for constructing with 18650 cells.    Materials needed:    2x 18650 or 21700 cells (they must both be exactly the same cell!)   Large shrink tube (alternative: electrical tape)   A balance plug and wire for it (or balance extension cord that you cut)   18 AWG wire (can be thicker if you need more amps)   Let‚Äôs first list the tools that I used:     Soldering iron   Hot glue gun   Wire cutters   Knife   Heat gun (optional)   Tweezers and soldering stand (optional)   Multimeter   Before you begin  Making a battery pack is dangerous. Ensure that you have a basic understanding electricity and lipo &amp; li-ion battery tech. This guide might not be perfect, so proceed at your own risk. Using battery cells incorrectly may lead to fire and physical harm. Treat them with the respect that they deserve. The author is not responsible for any damage or harm that may happen from following the steps in this document.  Steps  First we start with two identical cells. These are Samsung INR21700-50E cells:    You can find the specifications of these cells here.  Before we actually start, please note that all wires should be pre-tinned. This will make it much easier to combine the components:    Now put the cells together. They must touch each other. I used 2 coasters to help me with that. You can then use a tool to align them vertically:    Carefully apply hot glue on one side of the cells. Make sure your glue gun doesn‚Äôt touch the cells, so you don‚Äôt melt the plastic wrapper. Let it dry for 30-60 seconds and then do the other side too:    Since I don‚Äôt have a spot, I need to solder them regularly. Before we can add solder to the cells, we need to remove the oxidised layer from the cells. I do this by scraping carefully with a knife. But the cell flat on the table and start scraping at the center of the contact point.    Heat the soldering iron to 450 C (842 F). Less might also work, but this is the temperature that I used. Put some solder on your iron, then put the soldering iron on the cell, then add a bunch more solder:    Let it cool and then clean off the resin:    You can test the strength of your weld by applying force with a knife on the edge of the solder. I had to hold my camera to take a picture, but you should hold the batteries with one hand, and then carefully apply a few kilograms of force with the other hand. Be careful to not cut yourself.    Repeat the knife scraping, soldering, cleaning and strength testing for all 4 contact points:    Cut a small piece of wire to length to connect 2 battery cells in the back:    Make a 2S (3-pin) balance cable to length, or cut one from an existing balance extension cable:      Solder the center cable of the balance connector to the back of the battery:      Fasten the balance cable with some hot glue. This will make it easier to work with:    Measure and cut the remaining 2 wires of the balance cable. Make sure the red cable goes to the positive side of the cell, and the black cable goes to the negative side of the other cell:    Then solder the two balance cables onto the cells:    Now solder an XT30 connector to the same contacts:    We‚Äôre about to make some covers to protect the top and bottom of the battery pack. Take some double-sided tape, cut it to length. Then apply kapton tape (or electrical tape?) on one side.      Measure some shrink tube. It should stick out about 8-10mm on each end of the cells:    Hold the lipo by all of its wires and use the heat gun to carefully heat the shrink tube. Your pack is now finished:    Since we used Samsung INR21700-50E cells, this battery pack is a 2S pack with 5000 mAh. Even though these are Li-Ion cells, they are charged to 4.2 V. The cut-off voltage is a mere 2.5 V! You can charge at maximum 4900 mA, but it‚Äôs advised to charge them slower. They can be discharged at 9800 mAh continuously, or 14700 mA pulse. (according to this page)  When using different cells than the ones above, make sure to look up the the specifications of these cells. The voltages and currents will very likely be different."
  },
  
  {
    "title": "Upgrading your merge requests",
    "url": "/posts/2020/02/26/upgrading-your-merge-requests.html",
    "categories": "posts",
    "tags": "software",
    "date": "2020-02-26 23:00:00 +0100",
    "content": "I did a write-up on how to improve merge request (or pull request) quality control on ING‚Äôs Medium Blog."
  },
  
  {
    "title": "Installing Linux Mint on a Surface Go",
    "url": "/posts/2019/08/13/surface-go-linux-mint.html",
    "categories": "posts",
    "tags": "software, linux",
    "date": "2019-08-13 00:28:00 +0200",
    "content": "This is a step-by-step guide describing the steps I took to install Linux Mint 19.2 on a Surface Go device as the sole OS.    After a botched Mint installation, I succeeded in my second attempt a day later. It was then that I realized the need to document the process, in case I ever needed to do this dance again.  This document contains my notes, that I rewrote into this post.    Before you start, it‚Äôs important to know that Linux Mint isn‚Äôt perfect on the Surface Go. The cameras don‚Äôt work, as there are no drivers available. I also currently have a non-working hybernate/sleep mode. This did work in the first few hours, so I‚Äôll investigate whether an apt-get update broke one of the applied fixes below.  In return, though, you get increased battery life, and arguably a better user experience. You‚Äôll also gain over 15 GB of disk space, and everything will feel more snappy.  This post was last updated at 2019-08-13 17:57:00 +0200.  Disclaimer  I have done my best to put all the details in here, but there is still a chance that some info is missing or incomplete. If you‚Äôre stuck, feel free to contact me and I‚Äôll see what I can do for you. However, there are no garantees and I take no responsibility if something goes wrong. If you follow this guide, you follow it at your own risk.  Prerequisites  If you succeed with the installation in one go, you only need a 2 GB USB storage device.  If you have a USB-A connector for your storage device, you‚Äôll also need an adapter or a hub.  You‚Äôll need some basic Bash/Terminal experience to complete this guide.  If something fails, you will likely need to reinstall Windows 10. To do that, you‚Äôll need an 16 GB USB storage device. Scroll down for information about the recovery process.  Let‚Äôs do this!  Preparing the USB drive     Download the 64 bit version of Linux Mint. Version 19.2 is what this guide is based on. I picked the Cinnamon-flavoured one, as this supposedly has the best touch support.   Download Rufus to prepare the USB drive. (alternatively, you can use UNetbootin)   Run Rufus and leave all the defaults, but double-check these settings:            Partition scheme: MBR       Target system: BIOS or UEFI       File system: FAT32           Click START.   When the process is done, eject the USB drive and insert it into the Surface.   Preparing to boot from USB  To boot from USB, you need to first open the UEFI/BIOS on your Surface:     Power off the Surface Go.   Keep volume down button pressed.   Press the power button.   Release volume up when you see the Windows logo.   In the BIOS:     Click on Boot Configuration and move USB Storage up the list.   Click on Security and set Secure Boot to disabled.   Click on Exit,   Save the settings and reboot.   Booting from USB  There should now be a blue screen with a warning about disk encryption. That‚Äôs because we‚Äôve just disabled Secure Boot, and Windows has issues with that. There should be a button on the screen to skip/cancel this step. Click that.  You should now see/find the Choose an option screen and then click Use a device.  There you can choose the item named Linpus boot option that should be visible.  If it isn‚Äôt visible, try the USB UEFI option.  Installing Mint  Follow the wizard. I chose to:     Not enable full disk encryption. (the extra password prompt doesn‚Äôt work well on tablet)   To enable the LVM option.   Encrypt my home folder.   Put a password on my BIOS.   To install the commercial (closed-source) software (For things like MP3 support, etc.)   Mint improvements  The following steps presume that you have some knowledge of terminal usage like Bash.  Fix WiFi:  The WiFi is now visible, but you can‚Äôt see any networks. I fixed it with this GitHub project:     Download the repo here.   Run sudo sh setup.sh   I downloaded the repo to a USB drive and copied it onto the Surface.  Fix Grub 30 second delay:  You‚Äôll probably notice a black screen with some boot options for 30 seconds. If you‚Äôre suffering from this, do the following:     Run sudo sed -i \"/recordfail_broken=/{s/1/0/}\" /etc/grub.d/00_header   Run sudo update-grub   Reboot   (source)  Firefox  Firefox is the default browser, but the screen estate isn‚Äôt great for tablets. There are also issues with touch, but they are fixable.  I found that Chromium was working much better out of the box. You can even get the top bar collapsed into the tab bar to gain some screen estate.  Hide cursor on touch  One thing I noticed, is that wherever I touched the screen, the mouse cursor would teleport to that position on the screen. Windows 10 automatically hides the cursor, so I went searching online and found a solution:  This project didn‚Äôt compile for me, even with all the tools installed, so I had to disable documentation part in the build process.     First install the build tools: sudo apt-get install build-essential ev libx11-dev libxi-dev   Then download unclutter-xfixes   Edit the Makefile, and comment out the manual stuff (at $(MANS) and install:)   .PHONY: install install: $(TARGET) mans \t$(INSTALL) -Dm 0755 \"$(TARGET)\" \"$(DESTDIR)$(BINDIR)/$(TARGET)\" #\t$(INSTALL) -Dm 0644 man/unclutter-xfixes.1 \"$(DESTDIR)$(MANDIR)/unclutter.1\" #\t$(INSTALL) -Dm 0644 -t \"$(DESTDIR)$(LICENSEDIR)/\" LICENSE   $(MANS): %.1: %.man #\ta2x --no-xmllint -f manpage \"$&lt;\"     echo Skipped manual      Run make   Run sudo make install   Ensures it starts automatically:            Open System Settings       Go to Startup Applications       add new one with command ‚Äúunclutter ‚Äìtouch‚Äù           One thing to note, is that when you are using the mouse, the first following touch on the screen will still act like a mouse click. This means if you‚Äôre switching from mouse to touch, and your intent is to scroll, you will actually click on whatever is under your finger. Any subsequent touches will be fine though. To avoid this, I generally just tap on a ‚Äòsafe‚Äô area first, when switching to touch.  Troubleshooting &amp; Notes  Windows 10 recovery  If anything fails, you‚Äôll need to reinstall Windows 10. Follow the official guide.  To boot the recovery drive:     Ensure your UEFI/BIOS is still configured to allow booting from an (untrusted) USB device.   Power off the Surface Go   Keep volume down button pressed   Press the power button   Release volume down when you see the Windows logo   Install Windows 10   Revert UEFI/BIOS to its original settings   Display scaling  Open System Settings and:     In General, Configure User interface scaling to Double (HiDPI)   In Login Window, its Settings tab, set HiDPI support to Enable   On-screen keyboard  Mint has 2 variants: ‚ÄúVirtual Keyboard‚Äù and ‚ÄúOnboard‚Äù.  Onboard is the one that can be used on your lock screen through the accessibility option. It can also be used on the desktop. I advise to solely rely on the Onboard variant, as it is more reliable and has more options.  Virtual Keyboard is prettier (follows the Mint theme), but was buggy as it glitched out and broke my screen layouts until reboot.  Final notes  It was an interesting learning experience, and I was happy to have things running smoothly. I was pleasantly surprised that some of my favorite apps are now readily available through the package manager, including Sublime Text and Steam!  Sources and relevant articles:     Surface Go with Linux review on SlashGear   Installing Linux on Surface-Series Devices on Reddit   Surface Go: First Impressions on Reddit"
  },
  
  {
    "title": "Introducing Spork 4.0.0",
    "url": "/posts/2017/05/14/introducing-spork-4.0.0.html",
    "categories": "posts",
    "tags": "software",
    "date": "2017-05-14 17:11:00 +0200",
    "content": "I‚Äôve been working hard on Spork 4.0.0 since last summer.    Spork is a high performance runtime annotation processing framework with implementations for Android and for dependency injection. It is intended as a replacement for Butter Knife and/or Dagger 2, that‚Äôs why its functionality is heavily modelled onto the design of these libraries.  Let‚Äôs take a look at the Android and dependency injection features‚Ä¶  Spork for Android  Here‚Äôs a code snippet of several Android bindings with the spork-android dependency:  @BindLayout(R.layout.activity_download) public class DownloadActivity extends Activity {      @BindView(R.id.download_button)     private Button downloadButton;      @BindFragment(R.id.details_fragment)     private DetailsFragment fragment;      public void onCreate(Bundle savedInstanceState) {         super.onCreate(savedInstanceState);                  Spork.bind(this); // bind() wires it all up!     }      @BindClick(R.id.other_button)     private void onClickButton(Button someButton) {         downloadManager.startDownload();     } }   By calling Spork.bind() in onCreate() the View, OnClickListener and the Fragment are all automatically resolved without the need for all that boilerplate code. This is all pretty much the same as with Spork 3.x  These are all the supported annotations:    @BindLayout   @BindView   @BindFragment   @BindResource   @BindClick   Spork Dependency Injection  The spork-inject library creates instances of your classes and satisfies their dependencies. Let‚Äôs first take a look at a regular constructor injection without spork-inject:  class CoffeeMug {     private Coffee coffee;     private Mug mug;      CoffeeMug(Coffee coffee, Mug mug) {         this.coffee = coffee;         this.mug = mug;     } }   Creating a CoffeeMug requires you to pass along its dependencies manually. This is not a difficult task for a simple object with simple dependencies, but it gets a lot more tedious with scopes and lifecycle considerations. Spork takes care of all that.  Spork can inject fields directly. In this example it obtains a Coffee and a Mug instance for the respective fields:  class CoffeeMug {     @Inject private Coffee coffee;     @Inject private Mug mug;      ... }   Spork also supports method injection, but Field injection is generally preferred.  Declaring Dependencies  In the above sample, a Coffee and Mug are injected. Of course these dependencies must come from somewhere.  Dependencies should be defined in a Module:  @Provides public Coffee provideCoffee() {     return new BlackCoffee(); }   A @Provides method can require dependencies on its own. These are passed on as method arguments and they are automatically resolved by Spork:  @Provides public Coffee provideCoffee(Water water, CoffeeBeans beans) {     return new BlackCoffee(water, beans); }   Modules  The @Provides-annotated methods above are placed in a Module. Modules are POJO objects that define a set of dependencies:  public class BrewModule {     @Provides     public Mug provideMug() {         return new MugWithPrint(\"Input Java, output Java.\");     }      @Provides     public Water provideWater() {         return new BoilingWater();     }      @Provides     public Beans provideBeans() {         return new ArabicaBeans();     }      @Provides     public Coffee provideCoffee(Water water, CoffeeBeans beans) {         return new BlackCoffee(water, beans);     } }   Building an ObjectGraph  One or more modules are used to build an object graph. Object graphs hold state such as your singletons and named instances.  Creating an ObjectGraph is easy:  ObjectGraph objectGraph = ObjectGraphs.builder()     .module(new BrewModule())     .build();   When putting it all together, the CoffeeMug can now be injected with an ObjectGraph made with the BrewModule:  class CoffeeMug {     @Inject private Coffee coffee;     @Inject private Mug mug;      public CoffeeMug() {         ObjectGraphs.builder()             .module(new BrewModule())             .build()             .inject(this); // same as calling Spork.bind(this, objectGraph)     } }   Scoped injection  A scoped instance is an instance that belongs to a specific ObjectGraph created at a specific level of the application. It is tied to the lifecycle of that ObjectGraph.  @Singleton is a predefined scope that is always available at the root ObjectGraph in your application. It is tied to the lifecycle of that ObjectGraph.  @Provides methods in a module can specify a scope. It can be used like this:  @Provides @Singleton public CoffeeService provideCoffeeService() {     return new CoffeeServiceImpl(); }   Scopes can also be made custom.  Check out the full spork-inject User Guide for more details.  Qualifiers  In some cases, you might want to identify an injection by some kind of identifier. This is done with a qualifier.  The @Named annotation is a qualifier that is available by default. It can be used in a module:  class WaterModule {     @Provides     @Named(\"cold\")     public Water provideColdWater() {         ...     }      @Provides     @Named(\"hot\")     public Water provideHotWater() {         ...     } }   WaterModule can then be used to inject a Faucet class with the same annotation:  class Faucet {     @Inject @Named(\"cold\") Water coldWater;      @Inject @Named(\"hot\") Water hotWater;      ... }   You can even create your own qualifier annotations.  Dependencies  All dependencies are hosted on jcenter, which is the default repository when developing Android projects.  To use dependency injection:  dependencies {     compile 'com.bytewelder.spork:spork-inject:4.0.0' }   To use Android bindings: dependencies {     compile 'com.bytewelder.spork:spork-android:4.0.0@aar' }   To use Android bindings with AppCompat/Support: dependencies {     compile 'com.bytewelder.spork:spork-android-support:4.0.0@aar' {         exclude group: 'com.android.support'     } }   Closing words  Check out the Spork website or the documentation for more information.  Please file bug reports and feature requests at Spork‚Äôs GitHub repo."
  },
  
  {
    "title": "Testing multithreaded code",
    "url": "/posts/2017/05/13/testing-multithreaded-code.html",
    "categories": "posts",
    "tags": "software",
    "date": "2017-05-13 13:54:00 +0200",
    "content": "Writing multi-threaded code for Java/Android is not the easiest of tasks. Making it testable can also be a challenge.    In this post I will share with you a way to make multi-threaded code more testable. Let‚Äôs first take a look at an implementation of a cache that can store named instances, including a null value‚Ä¶ and let‚Äôs for the (in)convenience forget about ConcurrentHashMap‚Ä¶  // Create a cache and a color factory Cache cache = new Cache(); Factory colorFactory = new Factory();  // Cache creates and returns a white object Object whiteObject = cache.getOrCreate(\"white\", colorFactory);  // Cache creates and returns a yellow object Object yellowObject = cache.getOrCreate(\"yellow\", colorFactory);  // Cache returns the same white object from before Object whiteObject2 = cache.getOrCreate(\"white\", colorFactory);   This is the implementation of Cache:  public class Cache {     private final Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;();      public Cache(Map&lt;String, Object&gt; map) {         this.map = map;     }      public Cache() {         this(new HashMap&lt;String, Object&gt;());     }      public Object getOrCreate(String name, Factory factory) {         synchronized(map) {             if (map.containsKey(name)) {                 return map.get(name);             } else {                 Object instance = factory.create(name);                 map.put(name, instance);                 return instance;             }         }     } }   And this is how the Factory looks like:  public interface Factory {     Object create(String name); }   Now we can start testing whether getOrCreate() creates the cache properly.  The following code uses Mockito for mocking and Hamcrest matchers for assertions:  // given HashMap&lt;String, Object&gt; map = spy(new HashMap&lt;String, Object&gt;()); Cache cache = new Cache(map); Factory factory = mock(Factory.class);  // when getting an object with the same key twice in a row cache.getOrCreate(\"something\", factory); cache.getOrCreate(\"something\", factory);  // then verify that the factory is called only once verify(factory).create(\"something\"); verifyNoMoreInteractions(factory); // and ensure the cache only has one item assertThat(map.size(), is(1));   But how do you test the correct usage of the synchronized block? You don‚Äôt! This is where Lock comes to play. Let‚Äôs refactor the example to use a Lock:  public class Cache {     private final Lock mapLock;     private final Map&lt;String, Object&gt; map;      public Cache(Map&lt;String, Object&gt; map, Lock mapLock) {         this.map = map;         this.mapLock = mapLock;     }      public Cache() {         this(new HashMap&lt;String, Object&gt;(), new ReentrantLock());     }      public Object getOrCreate(String name, Factory factory) {         mapLock.lock();          try {             if (map.containsKey(name)) {                 return map.get(name);             } else {                 Object instance = factory.create(name);                 map.put(name, instance);                 return instance;             }         } finally {             mapLock.unlock();         }     } }   Now we can test whether our locking mechanism is used correctly:  // given HashMap&lt;String, Object&gt; map = spy(new HashMap&lt;String, Object&gt;()); Lock mapLock = spy(new ReentrantLock()); Cache cache = new Cache(map, mapLock); Factory factory = mock(Factory.class); String name = \"something\";  // when getOrCreate() is called, ignoring the result cache.getOrCreate(name, factory);  // verify that the following methods are called in order InOrder inOrder = inOrder(map, mapLock); inOrder.verify(mapLock).lock(); inOrder.verify(map).containsKey(name); inOrder.verify(map).put(name, null); inOrder.verify(mapLock).unlock(); inOrder.verifyNoMoreInteractions();   We can also verify the expected behavior when an Exception is thrown:  // given HashMap&lt;String, Object&gt; map = spy(new HashMap&lt;String, Object&gt;()); Cache cache = new Cache(map, mapLock); Factory factory = mock(Factory.class);  // given that creating a new item throws an exception when(factory.create(any(String.class))).thenThrow(new RuntimeException(\"test\"));  // when we create a new item for our cache try {     cache.getOrCreate(\"something\", factory); } catch (ObjectGraphException caught) {     // catch, but do nothing }  // verify that there was locking and unlocking in the correct order InOrder inOrder = inOrder(mapLock); inOrder.verify(mapLock).lock(); inOrder.verify(mapLock).unlock(); inOrder.verifyNoMoreInteractions(); // and assure nothing is stored in our map since the operation failed assertThat(map.isEmpty(), is(true));   As you can see, there is no need to start threads to test correct usage of locks. We don‚Äôt really need to know whether the Lock implementation works: We just want to see if our code is using it correctly in case the code is changed in the future.  This approach keeps your tests simple, readable and lightning fast to execute.  This does not cover everything there regarding synchronization, but it‚Äôs at least a way to improve the testability of your code."
  },
  
  {
    "title": "Borrowing from Kotlin",
    "url": "/posts/2017/05/08/borrowing-from-kotlin.html",
    "categories": "posts",
    "tags": "software",
    "date": "2017-05-08 23:17:00 +0200",
    "content": "Not all projects can be easily migrated to Kotlin, but that doesn‚Äôt mean we can‚Äôt benefit from Kotlin within other languages.    One of the things we can borrow from Kotlin in Java/Android is its clever naming scheme for constructing/converting objects. Kotlin comes with various methods such as mutableListOf():  val list = mutableListOf(1, 2, 3)   This allows Kotlin to define new static mapping/construction methods in a consistent manner. Kotlin follows a naming scheme where YourClass becomes a static method yourClassOf(...).  The benefit of using this in Java lies within your development environment. Once you type yourClassOf, you can summon up all implementations that create an instance of YourClass. In Android Studio or IntelliJ, you just press F1:    So why not apply the same idiom to Java?"
  }
  
]

